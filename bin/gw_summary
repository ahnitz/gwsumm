#!/usr/bin/env python
# coding=utf-8
# Copyright (C) Duncan Macleod (2013)
#
# This file is part of GWSumm.
#
# GWSumm is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# GWSumm is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with GWSumm.  If not, see <http://www.gnu.org/licenses/>.

"""The gravitational-wave interferometer summary information system.

This module provides the command-line interface to the GWSumm package,
allowing generation of detector summary information.

Select a <mode> to run over a calendar amount of time ('day', 'week',
or 'month'), or an arbitrary GPS (semi-open) interval.

Run 'gw_summary <mode> --help' for details of the specific arguments and
options acceptable for each mode.
"""

from __future__ import division

import datetime
import argparse
import calendar
import getpass
import warnings
import httplib

warnings.filterwarnings('ignore', 'TimeSeries.crop given GPS start')
warnings.filterwarnings('ignore', 'TimeSeries.crop given GPS end')
warnings.filterwarnings('ignore', category=RuntimeWarning)

try:
    import ROOT
except ImportError:
    pass
else:
    ROOT.PyConfig.IgnoreCommandLineOptions = True

from matplotlib import use
use('Agg')

# set matplotlib backend
try:
    from collections import OrderedDict
except ImportError:
    from astropy.utils import OrderedDict

from astropy import units

from gwpy.segments import (Segment, SegmentList)
from gwpy.time import (tconvert, to_gps, Time)
from gwpy.spectrum import psd

from gwsumm import (globalv, version, mode, html)
from gwsumm.config import *
from gwsumm.data import get_channels
from gwsumm.tabs import get_tab
from gwsumm.utils import *
from gwsumm.state import *
from gwsumm.data import get_timeseries_dict

__version__ = version.version
__author__ = 'Duncan Macleod <duncan.macleod@ligo.org>'

# find channels
re_channel = re.compile('[A-Z]\d:[A-Z]+-[A-Z0-9_]+(\.[a-z]+)?(,[a-z\-]+)?\Z')

# XXX HACK: disable colon separator in ConfigParser
GWSummConfigParser.OPTCRE = re.compile(
    r'(?P<option>[^=\s][^=]*)\s*(?P<vi>[=])\s*(?P<value>.*)$')

VERBOSE = False
PROFILE = False

# ----------------------------------------------------------------------------
# Argparse customisations

# find today's date
TODAY = datetime.datetime.utcnow().strftime('%Y%m%d')


# define custom parser
class GWArgumentParser(argparse.ArgumentParser):
    def __init__(self, *args, **kwargs):
        super(GWArgumentParser, self).__init__(*args, **kwargs)
        self._positionals.title = 'Positional arguments'
        self._optionals.title = 'Optional arguments'


# define custom help formatting (4-space)
class GWHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault('indent_increment', 4)
        super(GWHelpFormatter, self).__init__(*args, **kwargs)


# define actions for formatting dates
class DateAction(argparse.Action):
    @staticmethod
    def set_gps_times(namespace, startdate, enddate):
        setattr(namespace, 'gpsstart', to_gps(startdate))
        setattr(namespace, 'gpsend', to_gps(enddate))

    def __call__(self, parser, namespace, values, option_string=None):
        try:
            date = datetime.datetime.strptime(values, self.DATEFORMAT)
        except ValueError:
            raise parser.error("%s malformed. Please format as %s"
                               % (self.dest.title(), self.METAVAR))
        else:
            self.set_gps_times(namespace, date,
                               date + datetime.timedelta(days=1))
            setattr(namespace, self.dest, date)
        return date


class DayAction(DateAction):
    DATEFORMAT = '%Y%m%d'
    METAVAR = 'YYYYMMDD'


class MonthAction(DateAction):
    DATEFORMAT = '%Y%m'
    METAVAR = 'YYYYMM'


class YearAction(DateAction):
    DATEFORMAT = '%Y'
    METAVAR = 'YYYY'


class GPSAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=False):
        try:
            values = float(values)
        except (TypeError, ValueError):
            pass
        setattr(namespace, self.dest, to_gps(values))

# ----------------------------------------------------------------------------
# Setup command-line parsing


# define top-level parser
parser = GWArgumentParser(
    formatter_class=GWHelpFormatter,
    description=__doc__,
    fromfile_prefix_chars='@',
    epilog="Arguments and options may be written into files and passed to "
           "%(prog)s as positional arguments prepended with '@', e.g. "
           "'%(prog)s @args.txt'. In this format, options must be give as "
           "'--argument=value', and not '--argument value'.")
parser.add_argument('-V', '--version', action='version',
                    version=__version__,
                    help="show program's version number and exit")

# define shared commands
sharedopts = GWArgumentParser(add_help=False)
verbosegroup = sharedopts.add_mutually_exclusive_group()
verbosegroup.add_argument('-v', '--verbose', action='store_true',
                          default=False, help="show verbose output")

# give configuration files
copts = sharedopts.add_argument_group("Configuration options",
                                      "Provide a number of INI-format "
                                      "configuration files")
copts.add_argument('-i', '--ifo', action='store', type=str, metavar='IFO',
                   help="Instrument to process. If this option is set in "
                        "the [DEFAULT] of any of the INI files, giving "
                        "it here is redundant.")
copts.add_argument('-f', '--config-file', action='append', type=str,
                   metavar='FILE', default=[],
                   help="INI file for analysis, may be given multiple times")
copts.add_argument('-t', '--process-tab', action='append', type=str,
                   help="process only this tab, can be given multiple times")

popts = sharedopts.add_argument_group("Process options",
                                      "Configure how this summary will be "
                                      "processed.")
popts.add_argument('--nds', action='store_true', default='guess',
                   help='use NDS as the data source')
popts.add_argument('--multi-process', action='store', type=int,
                   default=1, dest='multiprocess', metavar='N',
                   help="use a maximum of N parallel processes at any time")
popts.add_argument('-b', '--bulk-read', action='store_true', default=False,
                   help="read all data up-front at the start of the job, "
                        "rather than when it is needed for a tab")
popts.add_argument('-S', '--on-segdb-error', action='store', type=str,
                   default='raise', choices=['raise', 'ignore', 'warn'],
                   help="action upon error fetching segments from SegDB")

# ----------------------------------------------------------------------------
# Define sub-parsers

# add HTML options
def add_output_options(parser_):
    """Add outuput options to the subparser.

    This is only needed because argparse can't handle mutually exclusive
    groups in a parent parser handed to a subparser for some reason.
    """
    outopts = parser_.add_argument_group("Output options")
    outopts.add_argument('-o', '--output-dir', action='store', type=str,
                         metavar='DIR', default=os.curdir,
                         help="Output directory for summary information")
    htmlopts = outopts.add_mutually_exclusive_group()
    htmlopts.add_argument('-m', '--html-only', action='store_true',
                          default=False,
                          help="Generate container HTML and navigation only")
    htmlopts.add_argument('-n', '--no-html', action='store_true',
                          default=False,
                          help="Generate inner HTML and contents only, not "
                               "supporting HTML")


# define hierarchichal archiving choise
def add_archive_options(parser_):
    """Add archiving options to the subparser.

    This is only needed because argparse can't handle mutually exclusive
    groups in a parent parser handed to a subparser for some reason.
    """
    hierarchopts = parser_.add_argument_group('Archive options')
    hierarchchoice = hierarchopts.add_mutually_exclusive_group()
    hierarchchoice.add_argument(
        '-a', '--archive', metavar='FILE_TAG', default=False,
        const='GW_SUMMARY_ARCHIVE', nargs='?',
        help="Read archived data from, and write processed data to "
             "an HDF archive file written with the FILE_TAG. If not "
             "given, no archive will be used, if given with no file "
             "tag, a default of '%(const)s' will be used.")
    hierarchchoice.add_argument(
        '-d', '--daily-archive', metavar='FILE_TAG', default=False,
        const='GW_SUMMARY_ARCHIVE',
        nargs='?', help="Read data from the daily archives, with the "
                        "given FILE_TAG. If not given, daily archives will be "
                        "used, if given with no file tag, a default of "
                        "'%(const)s' will be used.")

# define sub-parser handler
subparsers = parser.add_subparsers(
    dest='mode', title='Modes',
    description='Note: all dates are defined with UTC boundaries.\n'
                'The valid modes are:')
subparser = dict()

# DAY mode
daydoc = """
Run %s over a full UTC day, and link this day to others with a calendar
built into the HTML navigation bar. In this mode you can also archive data
in HDF-format files to allow progressive processing of live data without
restarting from scratch every time.""" % parser.prog
subparser['day'] = subparsers.add_parser('day', description=daydoc,
                                         epilog=parser.epilog,
                                         parents=[sharedopts],
                                         formatter_class=GWHelpFormatter,
                                         help="Process one day of data")
subparser['day'].add_argument('day', action=DayAction, type=str, nargs='?',
                              metavar=DayAction.METAVAR, default=TODAY,
                              help="Day to process")
add_output_options(subparser['day'])

darchopts = subparser['day'].add_argument_group('Archive options',
                                                'Choose if, and how, to '
                                                'archive data from this run')
darchopts.add_argument('-a', '--archive', metavar='FILE_TAG',
                       default=False, const='GW_SUMMARY_ARCHIVE', nargs='?',
                       help="Read archived data from, and write processed data "
                            "to, an HDF archive file written with the "
                            "FILE_TAG. If not given, no archive will be used, "
                            "if given with no file tag, a default of "
                            "'%(const)s' will be used.")

# WEEK mode
subparser['week'] = subparsers.add_parser('week', parents=[sharedopts],
                                          epilog=parser.epilog,
                                          formatter_class=GWHelpFormatter,
                                          help="Process one week of data")
subparser['week'].add_argument('week', action=DayAction, type=str,
                               metavar=DayAction.METAVAR,
                               help="Week to process (given as starting day)")
add_output_options(subparser['week'])
add_archive_options(subparser['week'])

# MONTH mode
subparser['month'] = subparsers.add_parser('month', parents=[sharedopts],
                                           epilog=parser.epilog,
                                           formatter_class=GWHelpFormatter,
                                           help="Process one month of data")
subparser['month'].add_argument('month', action=MonthAction, type=str,
                                metavar=MonthAction.METAVAR,
                                help="Month to process")
add_output_options(subparser['month'])
add_archive_options(subparser['month'])

# and GPS mode
subparser['gps'] = subparsers.add_parser('gps', parents=[sharedopts],
                                         epilog=parser.epilog,
                                         formatter_class=GWHelpFormatter,
                                         help="Process GPS interval")
subparser['gps'].add_argument('gpsstart', action=GPSAction, type=str,
                              metavar='GPSSTART', help='GPS start time.')
subparser['gps'].add_argument('gpsend', action=GPSAction, type=str,
                              metavar='GPSEND', help='GPS end time.')
add_output_options(subparser['gps'])

# ----------------------------------------------------------------------------
# Parse command-line and sanity check

opts = parser.parse_args()

# set verbose output options
globalv.VERBOSE = opts.verbose

# find all config files
opts.config_file = [os.path.expanduser(fp) for csv in opts.config_file for
                    fp in csv.split(',')]

# check segdb option
if not opts.on_segdb_error in ['raise', 'warn', 'ignore']:
    parser.error("Invalid option --on-segdb-error='%s'" % opts.on_segdb_error)

# read configuration file
config = GWSummConfigParser(dict_type=OrderedDict)
config.optionxform = str
if opts.ifo:
    config.set(DEFAULTSECT, 'ifo', opts.ifo)
config.set(DEFAULTSECT, 'user', getpass.getuser())
config.read(opts.config_file)
config.files = map(os.path.abspath, opts.config_file)

try:
    ifo = config.get(DEFAULTSECT, 'ifo')
except NoOptionError:
    ifo = None

# interpolate section names
for section in config.sections():
    if section.startswith('%(ifo)s'):
        if not ifo:
            e =  InterpolationMissingOptionError(
                     'ifo', 'DEFAULT', '%(ifo)s', section)
            e.args = ('%s\n%s' % (str(e), "Please give --ifo on the command "
                      "line, or specify 'ifo = XX' in the [DEFAULT] section "
                      "of the INI file to use interpolation in [section] "
                      "names"),)
            raise e
        s2 = section.replace('%(ifo)s', ifo)
        config._sections[s2] = config._sections.pop(section)

# double-check week mode matches calendar setting
if opts.mode == 'week':
    if config.has_option("calendar", "start-of-week"):
        weekday = getattr(calendar,
                          config.get("calendar", "start-of-week").upper())
        if weekday != opts.week.timetuple().tm_wday:
            msg = ("Cannot process week starting on %s. The "
                   "'start-of-week' option in the [calendar] section "
                   "of the INI file specifies weeks start on %ss."
                   % (opts.week.strftime('%Y%m%d'),
                      config.get("calendar", "start-of-week")))
            raise parser.error(msg)

# record times in ConfigParser
span = Segment(opts.gpsstart, opts.gpsend)
utc = tconvert(opts.gpsstart)
config.set(DEFAULTSECT, 'gps-start-time', str(int(opts.gpsstart)))
config.set(DEFAULTSECT, 'gps-end-time', str(int(opts.gpsend)))
config.set(DEFAULTSECT, 'yyyy', utc.strftime('%Y'))
config.set(DEFAULTSECT, 'mm', utc.strftime('%m'))
config.set(DEFAULTSECT, 'dd', utc.strftime('%d'))
config.set(DEFAULTSECT, 'yyyymm', utc.strftime('%Y%m'))
config.set(DEFAULTSECT, 'yyyymmdd', utc.strftime('%Y%m%d'))
config.set(DEFAULTSECT, 'duration', str(int(opts.gpsend - opts.gpsstart)))

starttime = Time(float(opts.gpsstart), format='gps')
endtime = Time(float(opts.gpsend), format='gps')

# set mode and output directory
mode.set_mode(mode.MODE_ENUM[opts.mode.upper()])
try:
    base = mode.get_base(utc)
except ValueError:
    base = os.path.join('%d-%d' % (opts.gpsstart, opts.gpsend))

# set LAL FFT plan wisdom level
duration = min(globalv.NOW, opts.gpsend) - opts.gpsstart
if duration > 200000:
     psd.LAL_FFTPLAN_LEVEL = 3
elif duration > 40000:
     psd.LAL_FFTPLAN_LEVEL = 2
else:
     psd.LAL_FFTPLAN_LEVEL = 1

# set processing options
if opts.multiprocess == 1:
    opts.multiprocess = False

# -----------------------------------------------------------------------------
# Setup

vprint("""
------------------------------------------------------------------------------
Welcome to the GW summary information system command-line interface
------------------------------------------------------------------------------

You have selected %s mode.
Start time %s (%s)
End time: %s (%s)
Output directory: %s
""" % (mode.MODE_NAME[mode.get_mode()], starttime.utc.iso, starttime.gps,
       endtime.utc.iso, endtime.gps,
       os.path.abspath(os.path.join(opts.output_dir, base))))

# Load custom units
try:
    customunits = config.nditems('units')
except NoSectionError:
    pass
else:
    new_ = []
    for unit, b in customunits:
        if b.lower() == 'dimensionless':
            b = ''
        new_.append(units.def_unit([unit], units.Unit(b)))
    units.add_enabled_units(new_)

if not opts.html_only:
    # parse channel grouns into individual sections
    for section in config.sections():
        if re.match('channels[-\s]', section):
            items = dict(config.nditems(section))
            try:
                names = split_channels(items.pop('channels'))
            except KeyError:
                raise NoOptionError('channels', section)
            for name in names:
                name = name.strip(' \n')
                if not config.has_section(name):
                    config.add_section(name)
                for key, val in items.iteritems():
                    if not config.has_option(name, key):
                        config.set(name, key, val)

    # read all channels
    channelsections = []
    for section in config.sections():
        if re_channel.match(section):
            channelsections.append(section)
    try:
        newchannels = get_channels(channelsections)
    except httplib.HTTPException:
        newchannels = []

    # read custom channel definitions
    for channel, section in zip(newchannels, channelsections):
        for key, val in nat_sorted(config.nditems(section),
                                   key=lambda x: x[0]):
            key = re_cchar.sub('_', key.rstrip())
            if key.isdigit():
                if not hasattr(channel, 'bits'):
                    channel.bits = []
                while len(channel.bits) < int(key):
                    channel.bits.append(None)
                channel.bits.append(val)
            else:
                try:
                    setattr(channel, key, eval(val.rstrip()))
                except NameError:
                    setattr(channel, key, val.rstrip())

# read states
try:
    load_states(config)
except NoSectionError:
    generate_all_state(*span)

# build directories
mkdir(opts.output_dir)
os.chdir(opts.output_dir)
plotdir = os.path.join(base, 'plots')
mkdir(plotdir)

# -----------------------------------------------------------------------------
# Read Archive

if not hasattr(opts, 'archive'):
    opts.archive = False

if opts.html_only:
    opts.archive = False
elif opts.archive is True:
    opts.archive = 'GW_SUMMARY_ARCHIVE'

if opts.archive:
    from gwsumm import archive
    archivedir = os.path.join(base, 'archive')
    mkdir(archivedir)
    opts.archive = os.path.join(archivedir, '%s-%s-%d-%d.hdf'
                                % (ifo, opts.archive, opts.gpsstart,
                                        opts.gpsend - opts.gpsstart))
    if os.path.isfile(opts.archive):
        vprint("Reading archived data from %s..." % opts.archive)
        archive.read_data_archive(opts.archive)
        vprint(" Done.\n")
    else:
        vprint("No archive found in %s, one will be created at the end.\n"
               % opts.archive)

# -----------------------------------------------------------------------------
# Read HTML configuration

try:
    css = [cval for (key, cval) in config.items('html') if
           re.match('css\d+', key)]
except NoSectionError:
    css = html.CSS
    javascript = html.JS
else:
    if not css:
        css = html.CSS
    javascript = [jval for (key, jval) in config.items('html') if
                  re.match('javascript\d+', key)]
    if not javascript:
        css = html.JS

# -----------------------------------------------------------------------------
# Read tabs

# read all tabs
alltabs = []
for section in filter(lambda n: re.match('tab[-\s]', n),
                      config.sections()):
    if not opts.process_tab or section[4:] in opts.process_tab:
        try:
            type_ = config.get(section, 'type')
        except NoOptionError:
            type_ = 'default'
        else:
            if not type_.startswith('archived-'):
                type_ = 'archived-%s' % type_
        DataTab = get_tab('archived-data')
        Tab = get_tab(type_)
        if issubclass(Tab, DataTab):
            tab = Tab.from_ini(config, section, plotdir=plotdir, base=base)
        else:
            tab = Tab.from_ini(config, section, base=base)
        alltabs.append(tab)

# sort tabs into hierarchical list
tabs = {}
# 1. Assume all tabs without parents are parents themselves
for tab in filter(lambda tab: tab.parent is None, alltabs):
    tabs[tab.name] = tab
# 2. All remaining tabs without a defined parent define that parent
# 3. Sort all tabs into their parent sets
for tab in filter(lambda tab: tab.parent is not None, alltabs):
    tabs.setdefault(tab.parent, get_tab('default')(tab.parent, *tab.span))
    tab.parent = tabs[tab.parent]
    tab.parent.add_child(tab)

tabs = tabs.values()

# write config page
about = get_tab('about')(span[0], span[1], parent=None, base=base)
if not opts.no_html:
    mkdir(about.path)
    about.write_html(css=css, js=javascript, tabs=tabs, config=config.files)


# -----------------------------------------------------------------------------
# Process all tabs

# XXX: bulk data reading could optimise things
if opts.bulk_read and not opts.html_only:
    vprint("\n-------------------------------------------------\n")
    vprint("Reading all data in BULK...\n")
    allts = set()
    allsv = set()
    allflags = set()
    for tab in alltabs:
        snames = []
        for state in tab.states:
            snames.append(state.name)
            if state.definition:
                allflags.update(re_flagdiv.split(state.definition))
        # get all data defined for the 'all' state
        if ALLSTATE in snames:
            allts.update(tab.get_channels('timeseries', 'spectrogram',
                                          'spectrum', 'histogram'))
            allsv.update(tab.get_channels('statevector'))
            allflags.update(tab.get_flags('segments'))
        # or get data for plots defined over all states
        else:
            for plot in tab.plots:
                if plot.state is not None:
                    continue
                if plot.type in ['timeseries', 'spectrogram', 'spectrum',
                                 'histogram']:
                    allts.update(plot.channels)
                elif plot.type in ['statevector']:
                    allsv.update(plot.channels)
                elif plot.type in ['segments']:
                    allflags.update([f for cflag in plot.flags for f in
                                     re_flagdiv.split(cflag)[::2] if f])
    allseg = SegmentList([span])
    if len(allflags):
        vprint("%d data-quality flags identified for segment query from all "
               "tabs...\n" % len(allflags))
        get_segments(allflags, allseg, config=config, return_=False)
    if len(allts):
        vprint("%d channels identified for TimeSeries from all tabs...\n"
               % len(allts))
        get_timeseries_dict(allts, allseg,
                            config=config, nds=opts.nds,
                            multiprocess=opts.multiprocess, return_=False)
    if len(allsv):
        vprint("%d channels identified for StateVector from all tabs...\n"
               % len(allsv))
        get_timeseries_dict(allsv, allseg,
                            config=config, nds=opts.nds, statevector=True,
                            multiprocess=opts.multiprocess, return_=False)

# find new ifo bases
ifobases = {}
try:
    bases_ = config.nditems('html')
except NoSectionError:
    pass
else:
    for key, val in config.nditems('html'):
        if re.search('-base\Z', key):
            ifobases[key.rsplit('-', 1)[0].upper()] = val
ifobases.pop(ifo, None)

# sort tabs by 'Summary', then lower case only, then everything else
_sort_tabs = lambda tab: ((tab.name == 'Summary' and tab.parent is None) and 1
                          or tab.name == 'Summary' and 2
                          or 'ODC' in tab.name and 3
                          or tab.name.islower() and tab.name.upper()
                          or tab.name.lower())

tabs.sort(key=_sort_tabs)
for tab in tabs:
    tab.children.sort(key=_sort_tabs)

alltabs.sort(key=_sort_tabs, reverse=True)
for tab in alltabs:
    mkdir(tab.href)
    vprint("\n-------------------------------------------------\n")
    if tab.parent:
        name = '%s/%s' % (tab.parent.name, tab.name)
    else:
        name = tab.name
    if not opts.html_only and isinstance(tab, get_tab('archived-data')):
        vprint("Processing %s\n" % name)
        tab.process(config=config, nds=opts.nds,
                    multiprocess=opts.multiprocess,
                    segdb_error=opts.on_segdb_error)
    if not tab.hidden:
        page = tab.write_html(css=css, js=javascript, tabs=tabs,
                              ifo=ifo, ifomap=ifobases, about=about.index,
                              writedata=not opts.html_only,
                              writehtml=not opts.no_html)
    vprint("%s complete!\n" % (name))

# -----------------------------------------------------------------------------
# Finalise

if opts.archive:
    vprint("\n-------------------------------------------------\n")
    vprint("Writing data to archive...")
    archive.write_data_archive(opts.archive)
    vprint("Done. Archive written in\n%s\n" % os.path.abspath(opts.archive))

vprint("""
------------------------------------------------------------------------------
All done. Thank you.
------------------------------------------------------------------------------
""")
